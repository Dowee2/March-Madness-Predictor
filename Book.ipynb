{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install --upgrade pandas\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "%pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%cd data/Mens/Season/\n",
    "games_df = pd.DataFrame()\n",
    "for season in range(2003 , 2025):\n",
    "    season_games = pd.read_csv(f'{season}/MRegularSeasonDetailedResults_{season}.csv')\n",
    "    games_df = pd.concat([games_df, season_games])\n",
    "\n",
    "ordinal_df = pd.DataFrame()\n",
    "for season in range(2003 , 2025):\n",
    "    ordinal_games = pd.read_csv(f'{season}/MMasseyOrdinals_{season}.csv')\n",
    "    ordinal_df = pd.concat([ordinal_df, ordinal_games])\n",
    "\n",
    "# ordinal_df = pd.read_csv('2024/MMasseyOrdinals_2024.csv')\n",
    "# games_df = pd.read_csv('2024/MRegularSeasonDetailedResults_2024.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# games_df['Week'] = ((games_df['DayNum']-1)/7 +1)\n",
    "# games_df['Week'] = games_df['Week'].apply(np.floor)\n",
    "\n",
    "\n",
    "# ordinal_df['Week'] = ((ordinal_df['RankingDayNum']-1)/7 +1)\n",
    "# ordinal_df['Week'] = ordinal_df['Week'].apply(np.floor)\n",
    "# games_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_additional_stats(df):\n",
    "    \"\"\"\n",
    "    Adds calculated statistics for two-point field goals to the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The original game results DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The modified DataFrame with additional stats.\n",
    "    \"\"\"\n",
    "    df['WFGM2'] = df['WFGM'] - df['WFGM3']\n",
    "    df['WFGA2'] = df['WFGA'] - df['WFGA3']\n",
    "    df['LFGM2'] = df['LFGM'] - df['LFGM3']\n",
    "    df['LFGA2'] = df['LFGA'] - df['LFGA3']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_team_stats(df):\n",
    "    \"\"\"\n",
    "    Prepares and aggregates team statistics and statistics against from game results.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The game results DataFrame with additional stats.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: A DataFrame with average stats per team and stats against.\n",
    "    \"\"\"\n",
    "    df = calculate_additional_stats(df)\n",
    "   # Stats when the team wins\n",
    "    win_stats = df[['Season','WTeamID', 'WFGM', 'WFGA', 'WFGM2', 'WFGA2', 'WFGM3', 'WFGA3', 'WFTM',\n",
    "                    'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']].copy()\n",
    "    win_stats.columns = ['Season','TeamID', 'FGM', 'FGA', 'FGM2', 'FGA2', 'FGM3', 'FGA3', 'FTM',\n",
    "                         'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF']\n",
    "\n",
    "    # Stats against the team when it wins (opponents' performance)\n",
    "    win_against_stats = df[['Season','WTeamID', 'LFGM', 'LFGA', 'LFGM2', 'LFGA2', 'LFGM3', 'LFGA3', 'LFTM',\n",
    "                            'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']].copy()\n",
    "    win_against_stats.columns = ['Season','TeamID', 'FGM', 'FGA', 'FGM2', 'FGA2', 'FGM3', 'FGA3',\n",
    "                                  'FTM', 'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl', \n",
    "                                  'Blk', 'PF']\n",
    "\n",
    "    # Stats when the team loses\n",
    "    lose_stats = df[['Season','LTeamID', 'LFGM', 'LFGA', 'LFGM2', 'LFGA2', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA',\n",
    "                     'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']].copy()\n",
    "    lose_stats.columns = ['Season','TeamID', 'FGM', 'FGA', 'FGM2', 'FGA2', 'FGM3', 'FGA3', 'FTM', 'FTA',\n",
    "                          'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF']\n",
    "\n",
    "    # Stats against the team when it loses (opponents' performance)\n",
    "    lose_against_stats = df[['Season','LTeamID', 'WFGM', 'WFGA', 'WFGM2', 'WFGA2', 'WFGM3', 'WFGA3', 'WFTM',\n",
    "                             'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']].copy()\n",
    "    lose_against_stats.columns = ['Season','TeamID', 'FGM', 'FGA', 'FGM2', 'FGA2', 'FGM3', 'FGA3',\n",
    "                                  'FTM', 'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl', \n",
    "                                  'Blk', 'PF']    \n",
    "\n",
    "    # Combine winning and losing stats\n",
    "    all_stats = pd.concat([win_stats, lose_stats])\n",
    "    all_against_stats = pd.concat([win_against_stats, lose_against_stats])\n",
    "\n",
    "    # Calculate the mean for stats and stats against separately\n",
    "    avg_stats = all_stats.groupby(['Season','TeamID']).mean().reset_index()\n",
    "    avg_against_stats = all_against_stats.groupby(['Season','TeamID']).mean().reset_index()\n",
    "\n",
    "    # Merge the average stats with average stats against\n",
    "    avg_merged_stats = pd.merge(avg_stats, avg_against_stats, on=['Season','TeamID'], suffixes=('', '_A'))\n",
    "    avg_merged_stats = avg_merged_stats.round(2)\n",
    "    return avg_merged_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# seasons = games_df['Season'].unique()\n",
    "# games_by_season = [games_df[games_df['Season'] == season] for season in seasons]\n",
    "    \n",
    "\n",
    "# teams_avg_stats = [prepare_team_stats(season) for season in games_by_season]\n",
    "team_avg_stats = prepare_team_stats(games_df)\n",
    "team_avg_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ordinal_df = ordinal_df.sort_values(by=['TeamID', 'RankingDayNum']).reset_index(drop=True)\n",
    "# ordinal_df = ordinal_df.rename(columns={'RankingDayNum':'DayNum'})\n",
    "\n",
    "# system_names = ordinal_df['SystemName'].unique()\n",
    "# teams_names = ordinal_df['TeamID'].unique()\n",
    "# system_no_rank_all_teams = []\n",
    "\n",
    "# for system in system_names:\n",
    "#     teams_in_system = ordinal_df[ordinal_df['SystemName'] == system]['TeamID'].unique()\n",
    "#     if len(teams_in_system) != len(teams_names):\n",
    "#         system_no_rank_all_teams.append(system)\n",
    "\n",
    "# ordinal_df = ordinal_df[~ordinal_df['SystemName'].isin(system_no_rank_all_teams)]\n",
    "# ordinal_pivot = ordinal_df.pivot_table(index=['TeamID', 'DayNum', 'Week'], columns='SystemName', values='OrdinalRank').reset_index()\n",
    "# ordinal_pivot.sort_values(by=['TeamID', 'DayNum'])\n",
    "# ordinal_pivot = ordinal_pivot.ffill()\n",
    "# ordinal_pivot = ordinal_pivot.groupby('TeamID').apply(lambda x: x.interpolate(method='linear', limit_direction='both')).reset_index(drop=True)\n",
    "\n",
    "# ordinal_df = ordinal_df.sort_values(by=['TeamID']).reset_index(drop=True)\n",
    "# ordinal_df = ordinal_df.drop(columns=['RankingDayNum'])\n",
    "\n",
    "# system_names = ordinal_df['SystemName'].unique()\n",
    "# teams_names = ordinal_df['TeamID'].unique()\n",
    "# system_no_rank_all_teams = []\n",
    "\n",
    "# for system in system_names:\n",
    "#     teams_in_system = ordinal_df[ordinal_df['SystemName'] == system]['TeamID'].unique()\n",
    "#     if len(teams_in_system) != len(teams_names):\n",
    "#         system_no_rank_all_teams.append(system)\n",
    "\n",
    "# ordinal_df = ordinal_df[~ordinal_df['SystemName'].isin(system_no_rank_all_teams)]\n",
    "# ordinal_pivot = ordinal_df.pivot_table(index=['TeamID'], columns='SystemName', values='OrdinalRank').reset_index()\n",
    "# ordinal_pivot.sort_values(by=['TeamID'])\n",
    "# ordinal_pivot = ordinal_pivot.groupby('TeamID').mean().reset_index()\n",
    "\n",
    "def prep_ordinal_ratings_for_merge(ordinal_df):\n",
    "    \"\"\"\n",
    "    Preprocesses the ordinal ratings dataframe for merging with other dataframes.\n",
    "    \n",
    "    Args:\n",
    "        ordinal_df (pandas.DataFrame): The ordinal ratings dataframe.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: The preprocessed ordinal ratings dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    ordinal_df = ordinal_df.sort_values(by=['Season','TeamID']).reset_index(drop=True)\n",
    "    ordinal_df = ordinal_df.drop(columns=['RankingDayNum'])\n",
    "\n",
    "    system_names = ordinal_df['SystemName'].unique()\n",
    "    teams_names = ordinal_df['TeamID'].unique()\n",
    "    system_no_rank_all_teams = []\n",
    "\n",
    "    for system in system_names:\n",
    "        teams_in_system = ordinal_df[ordinal_df['SystemName'] == system]['TeamID'].unique()\n",
    "        if len(teams_in_system) != len(teams_names):\n",
    "            system_no_rank_all_teams.append(system)\n",
    "\n",
    "    ordinal_df = ordinal_df[~ordinal_df['SystemName'].isin(system_no_rank_all_teams)]\n",
    "    ordinal_pivot = ordinal_df.pivot_table(index=['Season','TeamID'], columns='SystemName',\n",
    "                                           values='OrdinalRank').reset_index()\n",
    "    ordinal_pivot.sort_values(by=['Season','TeamID'])\n",
    "    ordinal_pivot = ordinal_pivot.ffill()\n",
    "    ordinal_pivot = ordinal_pivot.groupby(['Season','TeamID']).apply(lambda x: x.interpolate(method='linear', limit_direction='both')).reset_index(drop=True)\n",
    "    ordinal_pivot = ordinal_pivot.groupby(['Season','TeamID']).mean().reset_index()\n",
    "    \n",
    "    return ordinal_pivot\n",
    "\n",
    "\n",
    "# ordinal_pivot[(ordinal_pivot['TeamID'] == 1104)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals_pivot = prep_ordinal_ratings_for_merge(ordinal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_avg_stats[(team_avg_stats['TeamID'] == 1104)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals_pivot.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# This code performs the following operations:\n",
    "\n",
    "# 1. Sorts the 'ordinal_pivot' DataFrame by 'TeamID' and 'DayNum' columns.\n",
    "# 2. Sorts the 'teams_stats_weekly_df' DataFrame by 'TeamID' and 'DayNum' columns.\n",
    "# 3. Merges the sorted 'teams_stats_weekly_df' and 'ordinal_pivot' DataFrames using 'DayNum' and 'TeamID' columns in a backward direction.\n",
    "# 4. Sorts the resulting DataFrame by 'TeamID' and 'DayNum' columns and resets the index.\n",
    "# 5. Extracts the columns starting from the 35th column and assigns them to 'rank_columns' variable.\n",
    "# 6. Fills the missing values in 'rank_columns' for each 'TeamID' using backward filling.\n",
    "# 7. Filters the resulting DataFrame to include only rows where 'TeamID' is equal to 1104.\n",
    "\n",
    "# Parameters:\n",
    "#     - ordinal_pivot: DataFrame containing ordinal rankings.\n",
    "#     - teams_stats_weekly_df: DataFrame containing weekly team statistics.\n",
    "\n",
    "# Returns:\n",
    "#     - weekly_stats_w_rating: DataFrame with sorted and merged data, filled with missing values, and filtered by 'TeamID' 1104.\n",
    "# \"\"\"\n",
    "# ordinals_pivot = ordinals_pivot.sort_values(by=['TeamID'])\n",
    "\n",
    "# teams_avg_stats = teams_avg_stats.sort_values(by=['TeamID'])\n",
    "# weekly_stats_w_rating = pd.merge(teams_avg_stats, ordinals_pivot, on='TeamID', suffixes=('', '_A'))\n",
    "# weekly_stats_w_rating = weekly_stats_w_rating.sort_values(by=['TeamID']).reset_index(drop=True)\n",
    "# rank_columns = weekly_stats_w_rating.columns[34:]\n",
    "\n",
    "# weekly_stats_w_rating[rank_columns] = weekly_stats_w_rating.groupby('TeamID')[rank_columns].bfill()\n",
    "# weekly_stats_w_rating = weekly_stats_w_rating.dropna(axis = 1, how= 'any')\n",
    "# weekly_stats_w_rating\n",
    "\n",
    "def merge_ratings_stats(ordinal_df, teams_stats_avg_df):\n",
    "    \"\"\"\n",
    "    Merge the ordinal dataframe and the teams' weekly stats \n",
    "    dataframe based on the 'TeamID' and 'DayNum' columns.\n",
    "    \n",
    "    Args:\n",
    "        ordinal_df (pandas.DataFrame): The ordinal dataframe containing the team ratings.\n",
    "        teams_stats_weekly_df (pandas.DataFrame): The teams' weekly stats dataframe.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: The merged dataframe with the team ratings and weekly stats.\n",
    "    \"\"\"\n",
    "    ordinal_df = ordinal_df.sort_values(by=['TeamID'])\n",
    "\n",
    "    teams_stats_avg_df = teams_stats_avg_df.sort_values(by=['Season','TeamID'])\n",
    "    avg_stats_w_rating = pd.merge(teams_stats_avg_df, ordinal_df, on=['Season','TeamID'], suffixes=('', '_A'))\n",
    "    avg_stats_w_rating = avg_stats_w_rating.sort_values(by=['Season','TeamID']).reset_index(drop=True)\n",
    "    rank_columns = avg_stats_w_rating.columns[34:]\n",
    "\n",
    "    # Fill the NaN values in the rank columns with the previous values for each team. If still NaN, then drop the column.\n",
    "    avg_stats_w_rating[rank_columns] = avg_stats_w_rating.groupby(['Season','TeamID'])[rank_columns].bfill()\n",
    "    avg_stats_w_rating = avg_stats_w_rating.dropna(axis = 1, how= 'any')\n",
    "    return avg_stats_w_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_stats = merge_ratings_stats(ordinals_pivot, team_avg_stats)\n",
    "merged_stats['Season'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_matchup_data(games_df, stats):\n",
    "    \"\"\"\n",
    "    Merges game data with team stats to prepare matchup data.\n",
    "\n",
    "    Parameters:\n",
    "    - games_df (DataFrame): The DataFrame containing game results.\n",
    "    - avg_stats (DataFrame): The DataFrame containing average stats per team.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Matchup data with team stats and game outcome.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "\n",
    "    for _, row in games_df.iterrows():\n",
    "        season = row['Season']\n",
    "        team_1, team_2 = sorted((row['WTeamID'], row['LTeamID']))\n",
    "        team_1_won = 1 if team_1 == row['WTeamID'] else 0\n",
    "        team_1_stats = stats.loc[(stats['TeamID'] == team_1)].add_prefix('team_1_').iloc[-1]\n",
    "        team_2_stats = stats.loc[(stats['TeamID'] == team_2)].add_prefix('team_2_').iloc[-1]\n",
    "\n",
    "        matchup_data = {\n",
    "            'Season': row['Season'],\n",
    "            'DayNum': row['DayNum'],\n",
    "            'team_1': team_1,\n",
    "            'team_2': team_2,\n",
    "            'team_1_won': team_1_won\n",
    "        }\n",
    "        matchup_data.update(team_1_stats)\n",
    "        matchup_data.update(team_2_stats)\n",
    "\n",
    "        processed_data.append(matchup_data)\n",
    "\n",
    "    return pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchup_data = []\n",
    "for season in merged_stats['Season'].unique():\n",
    "    season_games = games_df[games_df['Season'] == season]\n",
    "    season_stats = merged_stats[merged_stats['Season'] == season]\n",
    "    matchup_data.append(prepare_matchup_data(season_games, season_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat(matchup_data)\n",
    "test.isna().sum().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_model_scalar(model_param, model_name, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3270)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Fit the model\n",
    "    model_param.fit(X_train_scaled, y_train)\n",
    "    y_pred = model_param.predict(X_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'{model_name} scalar accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model_param, model_name, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3270)\n",
    "\n",
    "    # sfs = SequentialFeatureSelector(model_param, n_features_to_select=10)\n",
    "    # sfs.fit(X_train, y_train)\n",
    "    # X_train = sfs.transform(X_train)\n",
    "    # X_test = sfs.transform(X_test)\n",
    "    model_param.fit(X_train, y_train)\n",
    "    y_pred = model_param.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'{model_name} accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matchups = prepare_matchup_data(games_df, weekly_stats_w_rating)\n",
    "\n",
    "X = test.drop(['DayNum','team_1_won'], axis=1)\n",
    "y = test['team_1_won']\n",
    "\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=3270, max_depth=10),\n",
    "    'Random Forest': RandomForestClassifier(random_state=3270, n_estimators=200, max_depth=10, min_samples_split=10, n_jobs=-1),\n",
    "    'Logistic Regression': LogisticRegression(random_state=3270, max_iter=1000, penalty = None, solver = 'lbfgs', ),\n",
    "    'XGBoost': XGBClassifier(random_state = 3270, n_estimators = 100, max_depth = 3, learning_rate = 0.1, gamma = 0, subsample = 0.8, colsample_bytree = 0.8)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    fit_model_scalar(model, name, X, y)\n",
    "    fit_model(model, name, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(random_state=3270, max_iter=1000, penalty = None, solver = 'lbfgs')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3270)\n",
    "\n",
    "lgr.fit(X_train, y_train)\n",
    "y_pred = lgr.predict(X_test)\n",
    "#Show the predictions and the actual values side by side\n",
    "pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}).tail(50)\n",
    "#Show the accuracy of the predictions for the last 50 games\n",
    "accuracy_score(y_test[len(y_test)-50:], y_pred[len(y_test)-50:])\n",
    "# accuracy_score(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasons_matchup_avgs_10_data = pd.DataFrame()\n",
    "# for season in range(2003 , 2025):\n",
    "#     season_games = pd.read_csv(f'{season}/MRegularSeasonDetailedResults_{season}_matchups_avg_w_rating.csv')\n",
    "#     seasons_matchup_avgs_10_data = pd.concat([seasons_matchup_avgs_10_data, season_games])\n",
    "\n",
    "seasons_matchup_avgs_10_data = test\n",
    "seasons = seasons_matchup_avgs_10_data['Season'].unique()\n",
    "data = seasons_matchup_avgs_10_data\n",
    "seasons_matchup_avgs_10_data = [seasons_matchup_avgs_10_data[seasons_matchup_avgs_10_data['Season'] == season] for season in seasons]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[(test['Season'] == 2024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeSeriesSplit_by_season(seasons_data):\n",
    "    \"\"\"\n",
    "    Splits the data into training and testing sets by season. Model is trained on all data up to a certain season and tested on the next season until the last season. \n",
    "\n",
    "    Parameters:\n",
    "    - seasons_data (list): A list of DataFrames containing data for each season.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of tuples containing training and testing sets for each season.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    model = LogisticRegression(random_state=3270, max_iter=1000, penalty = None, solver = 'lbfgs')\n",
    "    accuracies = []\n",
    "    for i in range(1, len(seasons_data)):\n",
    "        print(f'Testing on Season {seasons_data[i][\"Season\"].unique()[0]}')\n",
    "        train = pd.concat(seasons_data[:i])\n",
    "        train = train.dropna(axis = 'columns', how= 'any')\n",
    "        X_train = train.drop(['Season','DayNum', 'team_1_TeamID', 'team_2_TeamID', 'team_1_won'], axis=1)\n",
    "        y_train = train['team_1_won']\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        test = seasons_data[i]\n",
    "        test = test.dropna(axis = 'columns', how= 'any')\n",
    "        X_test = test.drop(['Season','DayNum','team_1_TeamID', 'team_2_TeamID', 'team_1_won'], axis=1)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        y_test = test['team_1_won']\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f'accuracy: {accuracy:.5f}')\n",
    "\n",
    "    print(f'Average accuracy: {np.mean(accuracies):.5f}')\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeSeriesSplit_by_season(seasons_matchup_avgs_10_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_matchups = seasons_matchup_avgs_10_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(60), (30,15), (60,15), (60,30,15)], \n",
    "    'activation': ['tanh', 'relu', 'logistic'],  \n",
    "    'solver': ['sgd', 'adam'], \n",
    "    'learning_rate': ['constant','adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "}\n",
    "model = MLPClassifier(random_state=3270)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "grid_search = GridSearchCV(model, param_grid, n_jobs=-1, verbose=2)\n",
    "\n",
    "all_except_last_season = pd.concat(season_matchups[:len(season_matchups)-1])\n",
    "last_season = pd.DataFrame(season_matchups[-1])\n",
    "X_train = all_except_last_season.drop(['Season','DayNum', 'team_1_TeamID', 'team_2_TeamID', 'team_1_won'], axis=1)\n",
    "y_train_ = all_except_last_season['team_1_won']\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = last_season.drop(['Season','DayNum','team_1_TeamID', 'team_2_TeamID', 'team_1_won'], axis=1)\n",
    "y_test = last_season['team_1_won']\n",
    "X_test = scaler.transform(X_test)\n",
    "fitted = grid_search.fit(X_train, y_train_)\n",
    "print(f'Best parameters: {fitted.best_params_}')\n",
    "y_pred = fitted.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'accuracy: {accuracy:.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(60), (30,15), (60,15), (60,30,15)], \n",
    "    'activation': ['tanh', 'relu', 'logistic'],  \n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'max_iter': [25, 50, 100],\n",
    "    'learning_rate': ['constant','adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "}\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(60), (30,15), (60,15), (60,30,15)],  # Sizes of the hidden layers\n",
    "    'activation': ['tanh', 'relu', 'logistic'],   # Activation function for the hidden layer\n",
    "    'solver': ['sgd', 'adam'],  # The solver for weight optimization\n",
    "    'learning_rate': ['constant','adaptive', 'invscaling'],  # Learning rate schedule for weight updates\n",
    "    'max_iter': [25, 50, 100, 200, 300],  # Maximum number of iterations\n",
    "}\n",
    "MLPClassifier(random_state = 3270, hidden_layer_sizes = (60,30,15), max_iter = 25, activation = 'logistic', learning_rate = 'invscaling')\n",
    "\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 10, 20, 30, 40],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10, 20],  # Minimum number of samples required to split an internal node\n",
    "    'criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "}\n",
    "DecisionTreeClassifier(random_state=3270,max_depth=10, min_samples_split=10)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "}\n",
    "RandomForestClassifier(random_state=3270, n_estimators=200, max_depth=10, min_samples_split=10, n_jobs=-1)\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],  # Type of norm used in the penalization\n",
    "    'solver': ['liblinear', 'saga'],  # Algorithm to use for optimization\n",
    "    'max_iter': [100, 50, 1000],  # Maximum number of iterations\n",
    "}\n",
    "LogisticRegression(random_state=3270, max_iter=1000, penalty = None, solver = 'lbfgs')\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of gradient boosted trees\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Boosting learning rate (xgb’s “eta”)\n",
    "    'max_depth': [3, 6, 9],  # Maximum depth of a tree\n",
    "    'subsample': [0.8, 1],  # Subsample ratio of the training instances\n",
    "    'colsample_bytree': [0.8, 1],  # Subsample ratio of columns when constructing each tree\n",
    "}\n",
    "XGBClassifier(random_state = 3270, n_estimators = 100, max_depth = 3,learning_rate = 0.1, gamma = 0, subsample = 0.8, colsample_bytree = 0.8)\n",
    "\n",
    "GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_tourney_data = []\n",
    "for season in range(2003 , 2025):\n",
    "    season_games = pd.read_csv(f'{season}/MRegularSeasonDetailedResults_{season}_avg_10_w_rating.csv')\n",
    "    seasons_tourney_data.append(season_games)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "please = pd.concat(seasons_tourney_data)\n",
    "len(please.columns) - len(please.isna().sum().drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats_season = {}\n",
    "for season in merged_stats['Season'].unique():\n",
    "    season_stats = merged_stats[merged_stats['Season'] == season]\n",
    "    team_stats_season[season] = season_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_game_matchups(bracket_team_matchups, team_stats):\n",
    "    \"\"\"\n",
    "    Builds matchup data for the tournament bracket.\n",
    "\n",
    "    Parameters:\n",
    "    - bracket_team_matchups (DataFrame): The DataFrame containing the current matchups for a bracket.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: A DataFrame where each row contains team_1's and team_2's stats for that specific matchup.\n",
    "    \"\"\"\n",
    "    matchups = []\n",
    "    for _, row in bracket_team_matchups.iterrows():\n",
    "        team_1 = row['StrongSeed']\n",
    "        team_2 = row['WeakSeed']\n",
    "\n",
    "        team_1_data = team_stats[team_stats['TeamID'] == team_1]\n",
    "        team_2_data = team_stats[team_stats['TeamID'] == team_2]\n",
    "        \n",
    "        team_1_data.columns = [f'team_1_{col}' for col in team_1_data.columns]\n",
    "        team_2_data.columns = [f'team_2_{col}' for col in team_2_data.columns]\n",
    "        \n",
    "        team_1_data = team_1_data.reset_index(drop=True)\n",
    "        team_2_data = team_2_data.reset_index(drop=True)\n",
    "        matchup_data = pd.concat([team_1_data, team_2_data], axis=1)\n",
    "        matchup_data['Slot'] = row['Slot']\n",
    "        matchups.append(matchup_data)\n",
    "    return pd.concat(matchups, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_playins(seeds_df):\n",
    "    \"\"\"\n",
    "    Preprocess the play in teams by removing 'a' and 'b' designations and preparing strong and weak seeds.\n",
    "    \n",
    "    Parameters:\n",
    "    - seeds_df (DataFrame): The DataFrame containing tournament seeds data, including 'Seed', 'TeamID' columns.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Processed DataFrame with 'StrongSeed' and 'WeakSeed' for play-in teams.\n",
    "    \"\"\"\n",
    "    playin_teams = seeds_df[seeds_df['Seed'].str.contains('a') | seeds_df['Seed'].str.contains('b')].copy()\n",
    "    playin_teams['Seed'] = playin_teams['Seed'].str.extract('([0-9A-Z]+)')\n",
    "    playin_teams_match_df = playin_teams.groupby('Seed')['TeamID'].apply(list).reset_index()\n",
    "    playin_teams_match_df['StrongSeed'] = playin_teams_match_df['TeamID'].apply(lambda x: x[0])\n",
    "    playin_teams_match_df['WeakSeed'] = playin_teams_match_df['TeamID'].apply(lambda x: x[1])\n",
    "    playin_teams_match_df.rename(columns={'Seed': 'Slot'}, inplace=True)\n",
    "    return playin_teams_match_df.drop(columns='TeamID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bracket_winners(bracket_matchups, model, scalar):\n",
    "    \"\"\"\n",
    "    Predict the winners in the lower bracket using a pre-trained model and scaler.\n",
    "    \n",
    "    Parameters:\n",
    "    - bracket_matchups (DataFrame): DataFrame of matchups in the lower bracket, excluding 'Seed' from scaling.\n",
    "    - model (Model): Pre-trained prediction model.\n",
    "    - scalar (Scaler): Pre-fitted scaler object for normalizing data.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Lower bracket DataFrame with an additional column 'team_1_won' indicating the predicted winner.\n",
    "    \"\"\"\n",
    "    bracket_matchups = bracket_matchups.drop(columns= [])\n",
    "    lower_bracket_scaled = scalar.fit_transform(bracket_matchups.drop(columns=['Slot']))\n",
    "    bracket_matchups['team_1_won'] = model.predict(lower_bracket_scaled)\n",
    "    return bracket_matchups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_seeds_with_winners(bracket, seeds_df):\n",
    "    \"\"\"\n",
    "    Update the seeds DataFrame with the winners from the lower bracket predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    - bracket (DataFrame): The lower bracket DataFrame with predictions.\n",
    "    - seeds_df (DataFrame): The original seeds DataFrame to be updated with current teams seedings.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Updated seeds DataFrame with winners.\n",
    "    \"\"\"\n",
    "    bracket_winners = {}\n",
    "    for _, row in bracket.iterrows():\n",
    "        slot = row['Slot']\n",
    "        if slot not in bracket_winners:\n",
    "            bracket_winners[slot] = []\n",
    "        bracket_winners[slot].append(row['team_1_TeamID'] if row['team_1_won'] == 1 else row['team_2_TeamID'])\n",
    "    \n",
    "    for curr_seed, team in bracket_winners.items():\n",
    "        seeds_df.loc[len(seeds_df.index)] = [curr_seed, team[0]]\n",
    "    seeds_df.sort_values(by='Seed', inplace=True)\n",
    "    return seeds_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_round_matchups(team_seeds, round_slots):\n",
    "    \"\"\"\n",
    "    Build the Tourney round matchups based on seeds and updates team slots.\n",
    "    \n",
    "    Parameters:\n",
    "    - team_seeds (DataFrame): DataFrame containing the seeds and corresponding team IDs.\n",
    "    - round_slots (DataFrame): DataFrame containing the slots for the tournament matchups.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: First-round matchups with updated team slots based on seeds.\n",
    "    \"\"\"\n",
    "\n",
    "    for index, row in round_slots.iterrows():\n",
    "        strong_team = team_seeds[(team_seeds['Seed'] == row['StrongSeed'])]['TeamID'].values[0]\n",
    "        weak_team = team_seeds[(team_seeds['Seed'] == row['WeakSeed'])]['TeamID'].values[0]\n",
    "        round_slots.at[index, 'StrongSeed'] = strong_team\n",
    "        round_slots.at[index, 'WeakSeed'] = weak_team\n",
    "\n",
    "    return round_slots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourney_seeds_df = pd.read_csv('2023/MNCAATourneySeeds_2023.csv')\n",
    "tourney_seeds_df.drop(columns=['Season'], inplace=True)\n",
    "tourney_slots_df = pd.read_csv('2023/MNCAATourneySlots_2023.csv')\n",
    "\n",
    "scalar = StandardScaler()\n",
    "\n",
    "playin_teams_match_df = preprocess_playins(tourney_seeds_df)\n",
    "bracket_matchups = build_game_matchups(playin_teams_match_df, team_stats_season[2023].groupby('TeamID').last().reset_index())\n",
    "bracket_matchups.columns\n",
    "bracket_matchups = predict_bracket_winners(bracket_matchups, model, scalar)\n",
    "tourney_seeds_df = update_seeds_with_winners(bracket_matchups, tourney_seeds_df)\n",
    "print('Done with play-ins')\n",
    "\n",
    "\n",
    "# curr_round_slots = tourney_slots_df[tourney_slots_df['Slot'].str.contains('R1')]\n",
    "\n",
    "# round_df = build_round_matchups(tourney_seeds_df,curr_round_slots)\n",
    "\n",
    "# current_round_bracket = build_game_matchups(round_df, team_stats_season[2023])\n",
    "# current_round_bracket.reset_index(drop=True, inplace=True)\n",
    "# current_round_bracket = predict_bracket_winners(current_round_bracket, model, scalar)\n",
    "# tourney_seeds_df = update_seeds_with_winners(current_round_bracket, tourney_seeds_df)\n",
    "\n",
    "\n",
    "rounds = ['R1', 'R2', 'R3', 'R4', 'R5', 'R6']\n",
    "# rounds = ['R1']\n",
    "matchups = []\n",
    "for current_round in rounds:\n",
    "    curr_round_slots = tourney_slots_df[tourney_slots_df['Slot'].str.contains(current_round)]\n",
    "\n",
    "    round_matchups = build_round_matchups(tourney_seeds_df,curr_round_slots)\n",
    "    matchups.append(round_matchups)\n",
    "    current_round_bracket = build_game_matchups(round_matchups, team_stats_season[2023].groupby('TeamID').last().reset_index())\n",
    "    current_round_bracket = predict_bracket_winners(current_round_bracket, model, scalar)\n",
    "    tourney_seeds_df = update_seeds_with_winners(current_round_bracket, tourney_seeds_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_bracket = pd.concat(matchups)\n",
    "complete_bracket.reset_index(drop=True, inplace=True)\n",
    "# complete_bracket.to_csv('2023/MNCAATourneyPredictions_matchup_2023.csv', index=False)\n",
    "complete_bracket\n",
    "\n",
    "# tourney_seeds_df\n",
    "# test_dict = {}\n",
    "# test_dict[type(lgr).__name__] = [accuracy_score(y_test, y_pred)]\n",
    "# test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cs3270p2_anton_maynard_train_save_load_all_models as tsm\n",
    "import os\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "models = tsm.load_models()\n",
    "rating10_models = models['rating_rol10']\n",
    "voting = VotingClassifier(estimators=[(name, model) for name, model in rating10_models.items()], voting='soft')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction_dir = 'data/Mens/Season/2024/predictions'\n",
    "prediction_file = 'MNCAATourneyPredictions_matchups_2024_rating_rol10_LogisticRegression.csv'\n",
    "seeds_df = 'MNCAATourneyPredictions__seeds_2024_rating_rol10_LogisticRegression.csv'\n",
    "\n",
    "matchups_df = pd.read_csv(os.path.join(prediction_dir, prediction_file))\n",
    "seeds_df = pd.read_csv(os.path.join(prediction_dir, seeds_df)).head(63)\n",
    "matchups_df.drop(columns=['Season'], inplace=True)\n",
    "seeds_df.rename(columns={'TeamID': 'Winner'}, inplace=True)\n",
    "\n",
    "\n",
    "merged_df = pd.merge(matchups_df,seeds_df , left_on='Slot', right_on='Seed', how='left')\n",
    "merged_df.drop(columns=['Seed'], inplace=True)\n",
    "\n",
    "merged_df\n",
    "## Get all files in a dir\n",
    "files = os.listdir(prediction_dir)\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    if \"matchups\" in file:\n",
    "        model_name = file.split('2024_')[-1].split('.')[0]\n",
    "        curr_matchups = pd.read_csv(os.path.join(prediction_dir, file))\n",
    "        curr_matchups.drop(columns=['Season'], inplace=True)\n",
    "        curr_matchups.rename(columns = {'StrongSeed' : 'StrongSeed_'+ model_name, 'WeakSeed' : 'WeakSeed_'+ model_name}, inplace=True)\n",
    "        \n",
    "        seed_file = file.replace('matchups', '_seeds')\n",
    "        curr_seeds = pd.read_csv(os.path.join(prediction_dir, seed_file))\n",
    "        curr_seeds.rename(columns = {'TeamID' : 'Winner_'+ model_name}, inplace=True)\n",
    "\n",
    "        curr_merge = pd.merge(curr_matchups, curr_seeds, left_on='Slot', right_on='Seed', how='left')\n",
    "        curr_merge.drop(columns=['Seed', 'Slot'], inplace=True)\n",
    "\n",
    "        merged_df = pd.concat([merged_df, curr_merge], axis=1)\n",
    "\n",
    "\n",
    "teams_names_df = pd.read_csv('data/Mens/MTeams.csv')\n",
    "\n",
    "team_names_map = teams_names_df.set_index('TeamID')['TeamName'].to_dict()\n",
    "\n",
    "for col in merged_df.columns[1:]:\n",
    "    merged_df[col] = merged_df[col].map(team_names_map)\n",
    "    \n",
    "# for index, row in pred_df.iterrows():\n",
    "#     strong_team = teams_names_df[teams_names_df['TeamID'] == row['StrongSeed']]['TeamName'].values[0]\n",
    "#     weak_team = teams_names_df[teams_names_df['TeamID'] == row['WeakSeed']]['TeamName'].values[0]\n",
    "#     pred_df.at[index, 'StrongSeed'] = strong_team\n",
    "#     pred_df.at[index, 'WeakSeed'] = weak_team\n",
    "\n",
    "merged_df.to_csv(os.path.join(prediction_dir,'MNCAATourneyPredictions.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tourney_seeds_df.head(63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.read_csv('data/Mens/Season/2023/MRegularSeasonDetailedResults_2023_avg_10_games.csv')\n",
    "stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.read_csv(f'data/Mens/Season/2023/MRegularSeasonDetailedResults_2023_avg_w_rating.csv')\n",
    "stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.read_csv(f'data/Mens/Season/2023/MRegularSeasonDetailedResults_2023_avg.csv')\n",
    "stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = pd.read_excel('2024_Bracket_Actuals_v_Preds.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values.columns\n",
    "need = values[['Models', 'Accuracy']]\n",
    "need = need[need['Models'].str.contains('Winner')]\n",
    "\n",
    "\n",
    "need['Models'] = need['Models'].str.replace('Winner_', '')\n",
    "need.sort_values(by='Accuracy', ascending=False)\n",
    "need.to_csv('2024_Winner_Accuracy.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values.columns\n",
    "strong = values[['Models', 'Accuracy']]\n",
    "strong = strong[strong['Models'].str.contains('Strong')]\n",
    "\n",
    "\n",
    "strong['Models'] = strong['Models'].str.replace('Strong_', '')\n",
    "strong.sort_values(by='Accuracy', ascending=False)\n",
    "strong.to_csv('2024_Strong_Accuracy.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values.columns\n",
    "weak = values[['Models', 'Accuracy']]\n",
    "weak = weak[weak['Models'].str.contains('Weak')]\n",
    "\n",
    "\n",
    "weak['Models'] = weak['Models'].str.replace('Weak_', '')\n",
    "weak.sort_values(by='Accuracy', ascending=False)\n",
    "weak.to_csv('2024_Weak_Accuracy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "def concat_seasons():\n",
    "    \"\"\"Concatenate seasons data into a single DataFrame.\"\"\"\n",
    "    data_location = 'data/Mens/Season/'\n",
    "    seasons = os.listdir(data_location)\n",
    "    all_seasons = pd.DataFrame()\n",
    "    for season in seasons:\n",
    "        curr_dir = os.path.join(data_location, season)\n",
    "        try:\n",
    "            season_df = pd.read_csv(\n",
    "                f'{curr_dir}/MRegularSeasonDetailedResults_{season}_matchups_avg_5_w_rating.csv')\n",
    "            all_seasons = pd.concat([all_seasons, season_df])\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "    return all_seasons\n",
    "\n",
    "def time_series_split_by_season(model, model_name, seasons_data):\n",
    "    \"\"\"Splits the data into training and testing sets by season.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    accuracies = []\n",
    "    print(f'Training {model_name} model...')\n",
    "    for i in range(1, len(seasons_data)):\n",
    "        print(f'Testing on Season {seasons_data[i][\"Season\"].unique()[0]}')\n",
    "        train = pd.concat(seasons_data[:i])\n",
    "        train = train.dropna(axis='columns', how='any')\n",
    "        x_train = train.drop(\n",
    "            ['Season', 'DayNum', 'team_1_TeamID', 'team_1_DayNum',\n",
    "             'team_1_Week_x', 'team_1_Week_y', 'team_2_TeamID', 'team_2_DayNum',\n",
    "             'team_2_Week_x','team_2_Week_y', 'team_1_won'], axis=1)\n",
    "        y_train = train['team_1_won']\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        test = seasons_data[i]\n",
    "        test = test.dropna(axis='columns', how='any')\n",
    "        x_test = test.drop(\n",
    "            ['Season', 'DayNum', 'team_1_TeamID', 'team_1_DayNum',\n",
    "             'team_1_Week_x', 'team_1_Week_y', 'team_2_TeamID', 'team_2_DayNum',\n",
    "             'team_2_Week_x','team_2_Week_y', 'team_1_won'], axis=1)\n",
    "        x_test = scaler.transform(x_test)\n",
    "        y_test = test['team_1_won']\n",
    "        # Train the model\n",
    "        history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "        test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "        print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "        print(f\"Test Loss: {test_loss:.3f}\")\n",
    "        # model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f'Accuracy: {accuracy:.5f}')\n",
    "\n",
    "    print(f'{model_name} avg scalar accuracy: {np.mean(accuracies):.5f}')\n",
    "    return model, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Assume X_train, y_train, X_test, y_test are already prepared\n",
    "\n",
    "# Normalize data\n",
    "\n",
    "seasons_df = concat_seasons()\n",
    "seasons_df = seasons_df.dropna(axis='columns', how='any')\n",
    "seasons = seasons_df['Season'].unique()\n",
    "seasons_data = [seasons_df[seasons_df['Season'] == season] for season in seasons]\n",
    "\n",
    "# Building the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # or 'softmax' for multiclass\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "_, accuracies = time_series_split_by_season(model, 'Neural Network', seasons_data)\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# # Evaluate the model\n",
    "# test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "# print(f\"Test Accuracy: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_df = concat_seasons()\n",
    "seasons_df = seasons_df.dropna(axis='columns', how='any')\n",
    "seasons = seasons_df['Season'].unique()\n",
    "seasons_data = [seasons_df[seasons_df['Season'] == season] for season in seasons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on Season 2011\n",
      "Epoch 1/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6059 - loss: 0.6453 - val_accuracy: 0.7026 - val_loss: 0.5688\n",
      "Epoch 2/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7386 - loss: 0.5178 - val_accuracy: 0.6906 - val_loss: 0.5890\n",
      "Epoch 3/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7546 - loss: 0.4956 - val_accuracy: 0.6963 - val_loss: 0.5786\n",
      "Epoch 4/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7633 - loss: 0.4774 - val_accuracy: 0.7019 - val_loss: 0.5837\n",
      "Epoch 5/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7879 - loss: 0.4470 - val_accuracy: 0.6891 - val_loss: 0.5921\n",
      "Epoch 6/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8097 - loss: 0.4179 - val_accuracy: 0.6952 - val_loss: 0.6386\n",
      "Epoch 7/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8194 - loss: 0.3964 - val_accuracy: 0.6811 - val_loss: 0.6253\n",
      "Epoch 8/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8229 - loss: 0.3689 - val_accuracy: 0.6763 - val_loss: 0.6767\n",
      "Epoch 9/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8524 - loss: 0.3352 - val_accuracy: 0.6822 - val_loss: 0.7114\n",
      "Epoch 10/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8856 - loss: 0.2744 - val_accuracy: 0.6756 - val_loss: 0.7421\n",
      "Epoch 11/50\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8969 - loss: 0.2543 - val_accuracy: 0.6698 - val_loss: 0.7934\n",
      "Epoch 11: early stopping\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step\n",
      "Testing on Season 2012\n",
      "Epoch 1/50\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7843 - loss: 0.4829 - val_accuracy: 0.6867 - val_loss: 0.5929\n",
      "Epoch 2/50\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8066 - loss: 0.4052 - val_accuracy: 0.6853 - val_loss: 0.5875\n",
      "Epoch 3/50\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8147 - loss: 0.3842 - val_accuracy: 0.6830 - val_loss: 0.5995\n",
      "Epoch 4/50\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8371 - loss: 0.3525 - val_accuracy: 0.6887 - val_loss: 0.6001\n",
      "Epoch 5/50\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8443 - loss: 0.3410 - val_accuracy: 0.6834 - val_loss: 0.6206\n",
      "Epoch 6/50\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8567 - loss: 0.3145 - val_accuracy: 0.6853 - val_loss: 0.5995\n",
      "Epoch 7/50\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8759 - loss: 0.2892 - val_accuracy: 0.6846 - val_loss: 0.6119\n",
      "Epoch 8/50\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8798 - loss: 0.2716 - val_accuracy: 0.6674 - val_loss: 0.6430\n",
      "Epoch 9/50\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8914 - loss: 0.2539 - val_accuracy: 0.6693 - val_loss: 0.6437\n",
      "Epoch 10/50\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9055 - loss: 0.2302 - val_accuracy: 0.6651 - val_loss: 0.6663\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step\n",
      "Testing on Season 2013\n",
      "Epoch 1/50\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.8147 - loss: 0.3895 - val_accuracy: 0.6825 - val_loss: 0.6042\n",
      "Epoch 2/50\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.8370 - loss: 0.3402 - val_accuracy: 0.6853 - val_loss: 0.6045\n",
      "Epoch 3/50\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8444 - loss: 0.3229 - val_accuracy: 0.6773 - val_loss: 0.6044\n",
      "Epoch 4/50\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.8577 - loss: 0.3090 - val_accuracy: 0.6761 - val_loss: 0.6186\n",
      "Epoch 5/50\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.8660 - loss: 0.2966 - val_accuracy: 0.6761 - val_loss: 0.6088\n",
      "Epoch 6/50\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.8713 - loss: 0.2828 - val_accuracy: 0.6756 - val_loss: 0.6242\n",
      "Epoch 7/50\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.8763 - loss: 0.2733 - val_accuracy: 0.6789 - val_loss: 0.6341\n",
      "Epoch 8/50\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.8863 - loss: 0.2560 - val_accuracy: 0.6613 - val_loss: 0.6515\n",
      "Epoch 9/50\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - accuracy: 0.8863 - loss: 0.2555 - val_accuracy: 0.6729 - val_loss: 0.6358\n",
      "Epoch 10/50\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.8927 - loss: 0.2384 - val_accuracy: 0.6656 - val_loss: 0.6699\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step\n",
      "Testing on Season 2014\n",
      "Epoch 1/50\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 0.8283 - loss: 0.3564 - val_accuracy: 0.6746 - val_loss: 0.6056\n",
      "Epoch 2/50\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 0.8405 - loss: 0.3351 - val_accuracy: 0.6936 - val_loss: 0.5926\n",
      "Epoch 3/50\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.8504 - loss: 0.3104 - val_accuracy: 0.6706 - val_loss: 0.5999\n",
      "Epoch 4/50\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 0.8502 - loss: 0.3178 - val_accuracy: 0.6809 - val_loss: 0.6013\n",
      "Epoch 5/50\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 0.8518 - loss: 0.3048 - val_accuracy: 0.6792 - val_loss: 0.6014\n",
      "Epoch 6/50\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 0.8649 - loss: 0.2947 - val_accuracy: 0.6815 - val_loss: 0.5983\n",
      "Epoch 7/50\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.8651 - loss: 0.2854 - val_accuracy: 0.6824 - val_loss: 0.6050\n",
      "Epoch 8/50\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 952us/step - accuracy: 0.8669 - loss: 0.2866 - val_accuracy: 0.6940 - val_loss: 0.5977\n",
      "Epoch 9/50\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 0.8727 - loss: 0.2710 - val_accuracy: 0.6874 - val_loss: 0.6029\n",
      "Epoch 10/50\n",
      "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 0.8703 - loss: 0.2711 - val_accuracy: 0.6762 - val_loss: 0.6063\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step\n",
      "Testing on Season 2015\n",
      "Epoch 1/50\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.8316 - loss: 0.3413 - val_accuracy: 0.6858 - val_loss: 0.5909\n",
      "Epoch 2/50\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.8367 - loss: 0.3323 - val_accuracy: 0.6821 - val_loss: 0.5933\n",
      "Epoch 3/50\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.8498 - loss: 0.3155 - val_accuracy: 0.6735 - val_loss: 0.6034\n",
      "Epoch 4/50\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.8508 - loss: 0.3139 - val_accuracy: 0.6737 - val_loss: 0.5929\n",
      "Epoch 5/50\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 0.8443 - loss: 0.3264 - val_accuracy: 0.6911 - val_loss: 0.5894\n",
      "Epoch 6/50\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.8494 - loss: 0.3128 - val_accuracy: 0.6756 - val_loss: 0.6136\n",
      "Epoch 7/50\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.8534 - loss: 0.3060 - val_accuracy: 0.6830 - val_loss: 0.5918\n",
      "Epoch 8/50\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 0.8602 - loss: 0.2950 - val_accuracy: 0.6866 - val_loss: 0.6046\n",
      "Epoch 9/50\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.8618 - loss: 0.2871 - val_accuracy: 0.6685 - val_loss: 0.5973\n",
      "Epoch 10/50\n",
      "\u001b[1m827/827\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 0.8573 - loss: 0.2932 - val_accuracy: 0.6759 - val_loss: 0.6012\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step\n",
      "Testing on Season 2016\n",
      "Epoch 1/50\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.8229 - loss: 0.3546 - val_accuracy: 0.6668 - val_loss: 0.5888\n",
      "Epoch 2/50\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 0.8333 - loss: 0.3321 - val_accuracy: 0.6886 - val_loss: 0.5779\n",
      "Epoch 3/50\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.8340 - loss: 0.3314 - val_accuracy: 0.6832 - val_loss: 0.5781\n",
      "Epoch 4/50\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.8368 - loss: 0.3347 - val_accuracy: 0.6916 - val_loss: 0.5789\n",
      "Epoch 5/50\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 0.8428 - loss: 0.3214 - val_accuracy: 0.6703 - val_loss: 0.5891\n",
      "Epoch 6/50\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.8366 - loss: 0.3371 - val_accuracy: 0.6776 - val_loss: 0.5886\n",
      "Epoch 7/50\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 0.8450 - loss: 0.3121 - val_accuracy: 0.6731 - val_loss: 0.5860\n",
      "Epoch 8/50\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8443 - loss: 0.3176 - val_accuracy: 0.6778 - val_loss: 0.5954\n",
      "Epoch 9/50\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8471 - loss: 0.3101 - val_accuracy: 0.6931 - val_loss: 0.5837\n",
      "Epoch 10/50\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 0.8510 - loss: 0.3061 - val_accuracy: 0.6830 - val_loss: 0.5956\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n",
      "Testing on Season 2017\n",
      "Epoch 1/50\n",
      "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 0.8184 - loss: 0.3619 - val_accuracy: 0.6528 - val_loss: 0.6126\n",
      "Epoch 2/50\n",
      "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8231 - loss: 0.3561 - val_accuracy: 0.6504 - val_loss: 0.6037\n",
      "Epoch 3/50\n",
      "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 0.8291 - loss: 0.3409 - val_accuracy: 0.6717 - val_loss: 0.5777\n",
      "Epoch 4/50\n",
      "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.8316 - loss: 0.3396 - val_accuracy: 0.6688 - val_loss: 0.5778\n",
      "Epoch 5/50\n",
      "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 0.8316 - loss: 0.3415 - val_accuracy: 0.6734 - val_loss: 0.5743\n",
      "Epoch 6/50\n",
      "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.8329 - loss: 0.3394 - val_accuracy: 0.6669 - val_loss: 0.5841\n",
      "Epoch 7/50\n",
      "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.3322 - val_accuracy: 0.6523 - val_loss: 0.5963\n",
      "Epoch 8/50\n",
      "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 0.3269 - val_accuracy: 0.6589 - val_loss: 0.5957\n",
      "Epoch 9/50\n",
      "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8333 - loss: 0.3287 - val_accuracy: 0.6725 - val_loss: 0.5810\n",
      "Epoch 10/50\n",
      "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.3276 - val_accuracy: 0.6869 - val_loss: 0.5769\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Testing on Season 2018\n",
      "Epoch 1/50\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8171 - loss: 0.3641 - val_accuracy: 0.6673 - val_loss: 0.5922\n",
      "Epoch 2/50\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8241 - loss: 0.3544 - val_accuracy: 0.6648 - val_loss: 0.5881\n",
      "Epoch 3/50\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8203 - loss: 0.3599 - val_accuracy: 0.6705 - val_loss: 0.5899\n",
      "Epoch 4/50\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 0.8237 - loss: 0.3554 - val_accuracy: 0.6851 - val_loss: 0.5839\n",
      "Epoch 5/50\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 0.8233 - loss: 0.3565 - val_accuracy: 0.6846 - val_loss: 0.5852\n",
      "Epoch 6/50\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.8268 - loss: 0.3449 - val_accuracy: 0.6834 - val_loss: 0.5827\n",
      "Epoch 7/50\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.8225 - loss: 0.3530 - val_accuracy: 0.6860 - val_loss: 0.5876\n",
      "Epoch 8/50\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.8219 - loss: 0.3556 - val_accuracy: 0.6888 - val_loss: 0.5864\n",
      "Epoch 9/50\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 0.8254 - loss: 0.3486 - val_accuracy: 0.6836 - val_loss: 0.5846\n",
      "Epoch 10/50\n",
      "\u001b[1m1331/1331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 0.8336 - loss: 0.3352 - val_accuracy: 0.6860 - val_loss: 0.5817\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step\n",
      "Testing on Season 2019\n",
      "Epoch 1/50\n",
      "\u001b[1m1499/1499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.8138 - loss: 0.3689 - val_accuracy: 0.6795 - val_loss: 0.5914\n",
      "Epoch 2/50\n",
      "\u001b[1m1499/1499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.8124 - loss: 0.3758 - val_accuracy: 0.6830 - val_loss: 0.5815\n",
      "Epoch 3/50\n",
      "\u001b[1m1499/1499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733us/step - accuracy: 0.8123 - loss: 0.3680 - val_accuracy: 0.6833 - val_loss: 0.5781\n",
      "Epoch 4/50\n",
      "\u001b[1m1499/1499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.8182 - loss: 0.3639 - val_accuracy: 0.6897 - val_loss: 0.5742\n",
      "Epoch 5/50\n",
      "\u001b[1m1499/1499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.8197 - loss: 0.3571 - val_accuracy: 0.6795 - val_loss: 0.5811\n",
      "Epoch 6/50\n",
      "\u001b[1m1499/1499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.8189 - loss: 0.3601 - val_accuracy: 0.6731 - val_loss: 0.5860\n",
      "Epoch 7/50\n",
      "\u001b[1m1499/1499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.8193 - loss: 0.3636 - val_accuracy: 0.6892 - val_loss: 0.5724\n",
      "Epoch 8/50\n",
      "\u001b[1m1499/1499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.8196 - loss: 0.3560 - val_accuracy: 0.6890 - val_loss: 0.5739\n",
      "Epoch 9/50\n",
      "\u001b[1m1499/1499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 0.8223 - loss: 0.3550 - val_accuracy: 0.6755 - val_loss: 0.5838\n",
      "Epoch 10/50\n",
      "\u001b[1m1499/1499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728us/step - accuracy: 0.8184 - loss: 0.3586 - val_accuracy: 0.6903 - val_loss: 0.5765\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step\n",
      "Testing on Season 2020\n",
      "Epoch 1/50\n",
      "\u001b[1m1670/1670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.8085 - loss: 0.3768 - val_accuracy: 0.6963 - val_loss: 0.5747\n",
      "Epoch 2/50\n",
      "\u001b[1m1670/1670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 749us/step - accuracy: 0.8138 - loss: 0.3732 - val_accuracy: 0.6944 - val_loss: 0.5741\n",
      "Epoch 3/50\n",
      "\u001b[1m1670/1670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.8104 - loss: 0.3760 - val_accuracy: 0.6944 - val_loss: 0.5757\n",
      "Epoch 4/50\n",
      "\u001b[1m1670/1670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.8120 - loss: 0.3779 - val_accuracy: 0.6896 - val_loss: 0.5735\n",
      "Epoch 5/50\n",
      "\u001b[1m1670/1670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 732us/step - accuracy: 0.8132 - loss: 0.3696 - val_accuracy: 0.6884 - val_loss: 0.5766\n",
      "Epoch 6/50\n",
      "\u001b[1m1670/1670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - accuracy: 0.8113 - loss: 0.3754 - val_accuracy: 0.6944 - val_loss: 0.5746\n",
      "Epoch 7/50\n",
      "\u001b[1m1670/1670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756us/step - accuracy: 0.8153 - loss: 0.3681 - val_accuracy: 0.6988 - val_loss: 0.5712\n",
      "Epoch 8/50\n",
      "\u001b[1m1670/1670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.8190 - loss: 0.3627 - val_accuracy: 0.6980 - val_loss: 0.5701\n",
      "Epoch 9/50\n",
      "\u001b[1m1670/1670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.8140 - loss: 0.3702 - val_accuracy: 0.6926 - val_loss: 0.5741\n",
      "Epoch 10/50\n",
      "\u001b[1m1670/1670\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.8182 - loss: 0.3614 - val_accuracy: 0.6959 - val_loss: 0.5716\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step\n",
      "Testing on Season 2021\n",
      "Epoch 1/50\n",
      "\u001b[1m1837/1837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.8087 - loss: 0.3786 - val_accuracy: 0.6887 - val_loss: 0.5797\n",
      "Epoch 2/50\n",
      "\u001b[1m1837/1837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8052 - loss: 0.3858 - val_accuracy: 0.6926 - val_loss: 0.5762\n",
      "Epoch 3/50\n",
      "\u001b[1m1837/1837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.8074 - loss: 0.3786 - val_accuracy: 0.6934 - val_loss: 0.5762\n",
      "Epoch 4/50\n",
      "\u001b[1m1837/1837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.8101 - loss: 0.3760 - val_accuracy: 0.6856 - val_loss: 0.5780\n",
      "Epoch 5/50\n",
      "\u001b[1m1837/1837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.8092 - loss: 0.3819 - val_accuracy: 0.6957 - val_loss: 0.5791\n",
      "Epoch 6/50\n",
      "\u001b[1m1837/1837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.8119 - loss: 0.3724 - val_accuracy: 0.6934 - val_loss: 0.5800\n",
      "Epoch 7/50\n",
      "\u001b[1m1837/1837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.8143 - loss: 0.3708 - val_accuracy: 0.6957 - val_loss: 0.5803\n",
      "Epoch 8/50\n",
      "\u001b[1m1837/1837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.8146 - loss: 0.3701 - val_accuracy: 0.6955 - val_loss: 0.5768\n",
      "Epoch 9/50\n",
      "\u001b[1m1837/1837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.8165 - loss: 0.3685 - val_accuracy: 0.6911 - val_loss: 0.5872\n",
      "Epoch 10/50\n",
      "\u001b[1m1837/1837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740us/step - accuracy: 0.8113 - loss: 0.3732 - val_accuracy: 0.6892 - val_loss: 0.5783\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step\n",
      "Testing on Season 2022\n",
      "Epoch 1/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.8069 - loss: 0.3799 - val_accuracy: 0.7080 - val_loss: 0.5636\n",
      "Epoch 2/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727us/step - accuracy: 0.8077 - loss: 0.3822 - val_accuracy: 0.7083 - val_loss: 0.5640\n",
      "Epoch 3/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.8106 - loss: 0.3743 - val_accuracy: 0.7109 - val_loss: 0.5606\n",
      "Epoch 4/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 767us/step - accuracy: 0.8082 - loss: 0.3816 - val_accuracy: 0.7126 - val_loss: 0.5610\n",
      "Epoch 5/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - accuracy: 0.8118 - loss: 0.3739 - val_accuracy: 0.7098 - val_loss: 0.5596\n",
      "Epoch 6/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 744us/step - accuracy: 0.8104 - loss: 0.3698 - val_accuracy: 0.7102 - val_loss: 0.5685\n",
      "Epoch 7/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.8088 - loss: 0.3769 - val_accuracy: 0.7094 - val_loss: 0.5657\n",
      "Epoch 8/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.8104 - loss: 0.3735 - val_accuracy: 0.7098 - val_loss: 0.5619\n",
      "Epoch 9/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8130 - loss: 0.3709 - val_accuracy: 0.7051 - val_loss: 0.5673\n",
      "Epoch 10/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 773us/step - accuracy: 0.8115 - loss: 0.3763 - val_accuracy: 0.7106 - val_loss: 0.5633\n",
      "Epoch 11/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 771us/step - accuracy: 0.8110 - loss: 0.3720 - val_accuracy: 0.7109 - val_loss: 0.5628\n",
      "Epoch 12/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 778us/step - accuracy: 0.8144 - loss: 0.3677 - val_accuracy: 0.7109 - val_loss: 0.5676\n",
      "Epoch 13/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 788us/step - accuracy: 0.8153 - loss: 0.3652 - val_accuracy: 0.7085 - val_loss: 0.5681\n",
      "Epoch 14/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 756us/step - accuracy: 0.8174 - loss: 0.3622 - val_accuracy: 0.7091 - val_loss: 0.5676\n",
      "Epoch 15/50\n",
      "\u001b[1m1957/1957\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752us/step - accuracy: 0.8146 - loss: 0.3636 - val_accuracy: 0.7085 - val_loss: 0.5671\n",
      "Epoch 15: early stopping\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step\n",
      "Testing on Season 2023\n",
      "Epoch 1/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 804us/step - accuracy: 0.8051 - loss: 0.3789 - val_accuracy: 0.6844 - val_loss: 0.5922\n",
      "Epoch 2/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 752us/step - accuracy: 0.8063 - loss: 0.3820 - val_accuracy: 0.6840 - val_loss: 0.5904\n",
      "Epoch 3/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 787us/step - accuracy: 0.8081 - loss: 0.3807 - val_accuracy: 0.6862 - val_loss: 0.5895\n",
      "Epoch 4/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 760us/step - accuracy: 0.8068 - loss: 0.3800 - val_accuracy: 0.6896 - val_loss: 0.5910\n",
      "Epoch 5/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 802us/step - accuracy: 0.8080 - loss: 0.3770 - val_accuracy: 0.6873 - val_loss: 0.5875\n",
      "Epoch 6/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 736us/step - accuracy: 0.8079 - loss: 0.3801 - val_accuracy: 0.6896 - val_loss: 0.5921\n",
      "Epoch 7/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 734us/step - accuracy: 0.8112 - loss: 0.3727 - val_accuracy: 0.6887 - val_loss: 0.5922\n",
      "Epoch 8/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 768us/step - accuracy: 0.8104 - loss: 0.3743 - val_accuracy: 0.6806 - val_loss: 0.5938\n",
      "Epoch 9/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 760us/step - accuracy: 0.8098 - loss: 0.3760 - val_accuracy: 0.6819 - val_loss: 0.5959\n",
      "Epoch 10/50\n",
      "\u001b[1m2124/2124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 768us/step - accuracy: 0.8135 - loss: 0.3711 - val_accuracy: 0.6890 - val_loss: 0.5898\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step\n",
      "Testing on Season 2024\n",
      "Epoch 1/50\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 761us/step - accuracy: 0.8039 - loss: 0.3880 - val_accuracy: 0.6886 - val_loss: 0.5845\n",
      "Epoch 2/50\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 778us/step - accuracy: 0.8021 - loss: 0.3893 - val_accuracy: 0.6900 - val_loss: 0.5763\n",
      "Epoch 3/50\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 783us/step - accuracy: 0.8025 - loss: 0.3870 - val_accuracy: 0.6886 - val_loss: 0.5800\n",
      "Epoch 4/50\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 744us/step - accuracy: 0.8062 - loss: 0.3851 - val_accuracy: 0.6915 - val_loss: 0.5782\n",
      "Epoch 5/50\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 772us/step - accuracy: 0.8040 - loss: 0.3859 - val_accuracy: 0.6913 - val_loss: 0.5820\n",
      "Epoch 6/50\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 754us/step - accuracy: 0.8072 - loss: 0.3793 - val_accuracy: 0.6893 - val_loss: 0.5870\n",
      "Epoch 7/50\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 783us/step - accuracy: 0.8018 - loss: 0.3863 - val_accuracy: 0.6920 - val_loss: 0.5811\n",
      "Epoch 8/50\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 733us/step - accuracy: 0.8049 - loss: 0.3794 - val_accuracy: 0.7007 - val_loss: 0.5765\n",
      "Epoch 9/50\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 775us/step - accuracy: 0.8078 - loss: 0.3786 - val_accuracy: 0.6899 - val_loss: 0.5796\n",
      "Epoch 10/50\n",
      "\u001b[1m2299/2299\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 738us/step - accuracy: 0.8044 - loss: 0.3870 - val_accuracy: 0.6936 - val_loss: 0.5760\n",
      "Epoch 10: early stopping\n",
      "\u001b[1m176/176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume X_train, y_train, X_test, y_test are already prepared\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "#     BatchNormalization(),\n",
    "#     Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "#     BatchNormalization(),\n",
    "#     Dense(32, activation='relu',),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Adding callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min'),\n",
    "    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "# Building the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # or 'softmax' for multiclass\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\"\"\"Splits the data into training and testing sets by season.\"\"\"\n",
    "    \n",
    "accuracies = []\n",
    "for i in range(1, len(seasons_data)):\n",
    "    print(f'Testing on Season {seasons_data[i][\"Season\"].unique()[0]}')\n",
    "    train = pd.concat(seasons_data[:i])\n",
    "    train = train.dropna(axis='columns', how='any')\n",
    "    x_train = train.drop(\n",
    "        ['Season', 'DayNum', 'team_1_TeamID', 'team_1_DayNum',\n",
    "            'team_1_Week_x', 'team_1_Week_y', 'team_2_TeamID', 'team_2_DayNum',\n",
    "            'team_2_Week_x','team_2_Week_y', 'team_1_won'], axis=1)\n",
    "    y_train = train['team_1_won']\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    test = seasons_data[i]\n",
    "    test = test.dropna(axis='columns', how='any')\n",
    "    x_test = test.drop(\n",
    "        ['Season', 'DayNum', 'team_1_TeamID', 'team_1_DayNum',\n",
    "            'team_1_Week_x', 'team_1_Week_y', 'team_2_TeamID', 'team_2_DayNum',\n",
    "            'team_2_Week_x','team_2_Week_y', 'team_1_won'], axis=1)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    y_test = test['team_1_won']\n",
    "    # Train the model\n",
    "    history = model.fit(x_train, y_train, epochs=50, batch_size=32, \n",
    "                    validation_data=(x_test, y_test), callbacks=callbacks)\n",
    "    # test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    # print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "    # print(f\"Test Loss: {test_loss:.3f}\")\n",
    "    # model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.801688414812088"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['accuracy']\n",
    "np.mean(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7993610501289368,\n",
       " 0.8000543713569641,\n",
       " 0.7996193766593933,\n",
       " 0.8017944693565369,\n",
       " 0.8027868270874023,\n",
       " 0.8024741411209106,\n",
       " 0.8003942370414734,\n",
       " 0.803167462348938,\n",
       " 0.8042958378791809,\n",
       " 0.8029363751411438]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['accuracy']\n",
    "# np.mean(history.history['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
