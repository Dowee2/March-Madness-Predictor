{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "%pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%cd data/Mens/Season/\n",
    "ordinal_df = pd.read_csv('2024/MMasseyOrdinals_2024.csv')\n",
    "games_df = pd.read_csv('2024/MRegularSeasonDetailedResults_2024.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df['Week'] = ((games_df['DayNum']-1)/7 +1)\n",
    "games_df['Week'] = games_df['Week'].apply(np.floor)\n",
    "\n",
    "\n",
    "ordinal_df['Week'] = ((ordinal_df['RankingDayNum']-1)/7 +1)\n",
    "ordinal_df['Week'] = ordinal_df['Week'].apply(np.floor)\n",
    "games_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_additional_stats(df):\n",
    "    \"\"\"\n",
    "    Adds calculated statistics for two-point field goals to the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The original game results DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: The modified DataFrame with additional stats.\n",
    "    \"\"\"\n",
    "    df['WFGM2'] = df['WFGM'] - df['WFGM3']\n",
    "    df['WFGA2'] = df['WFGA'] - df['WFGA3']\n",
    "    df['LFGM2'] = df['LFGM'] - df['LFGM3']\n",
    "    df['LFGA2'] = df['LFGA'] - df['LFGA3']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_team_stats(df):\n",
    "    \"\"\"\n",
    "    Prepares and aggregates team statistics and statistics against from game results.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The game results DataFrame with additional stats.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: A DataFrame with average stats per team and stats against.\n",
    "    \"\"\"\n",
    "    df = calculate_additional_stats(df)\n",
    "    # Stats when the team wins\n",
    "    win_stats = df[['WTeamID','DayNum','Week', 'WFGM', 'WFGA', 'WFGM2', 'WFGA2', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']].copy()\n",
    "    win_stats.columns = ['TeamID','DayNum','Week', 'FGM', 'FGA', 'FGM2', 'FGA2', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF']\n",
    "    \n",
    "    # Stats against the team when it wins (opponents' performance)\n",
    "    win_against_stats = df[['WTeamID','DayNum','Week', 'LFGM', 'LFGA', 'LFGM2', 'LFGA2', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']].copy()\n",
    "    win_against_stats.columns = ['TeamID','DayNum','Week', 'FGMA', 'FGAA', 'FGM2A', 'FGA2A', 'FGM3A', 'FGA3A', 'FTMA', 'FTAA', 'ORA', 'DRA', 'AstA', 'TOA', 'StlA', 'BlkA', 'PFA']\n",
    "\n",
    "    # Stats when the team loses\n",
    "    lose_stats = df[['LTeamID','DayNum','Week', 'LFGM', 'LFGA', 'LFGM2', 'LFGA2', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF']].copy()\n",
    "    lose_stats.columns = ['TeamID', 'DayNum','Week','FGM', 'FGA', 'FGM2', 'FGA2', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl', 'Blk', 'PF']\n",
    "    \n",
    "    # Stats against the team when it loses (opponents' performance)\n",
    "    lose_against_stats = df[['LTeamID','DayNum','Week','WFGM', 'WFGA', 'WFGM2', 'WFGA2', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl', 'WBlk', 'WPF']].copy()\n",
    "    lose_against_stats.columns = ['TeamID','DayNum','Week', 'FGMA', 'FGAA', 'FGM2A', 'FGA2A', 'FGM3A', 'FGA3A', 'FTMA', 'FTAA', 'ORA', 'DRA', 'AstA', 'TOA', 'StlA', 'BlkA', 'PFA']\n",
    "\n",
    "    # Combine winning and losing stats\n",
    "    all_stats = pd.concat([win_stats, lose_stats]).sort_values(by=['TeamID', 'DayNum'])\n",
    "    all_against_stats = pd.concat([win_against_stats, lose_against_stats]).sort_values(by=['TeamID', 'DayNum'])\n",
    "\n",
    "    Week_DayNum_for =  all_stats[['TeamID', 'DayNum', 'Week']].reset_index(drop=True)\n",
    "    Week_DayNum_against = all_against_stats[['TeamID', 'DayNum', 'Week']].reset_index(drop=True)\n",
    "\n",
    "    all_stats.drop(columns=['Week', 'DayNum'], inplace=True)\n",
    "    all_against_stats.drop(columns=['Week', 'DayNum'], inplace=True)\n",
    "\n",
    "    stats_rolling = all_stats.groupby('TeamID').rolling(window=10, min_periods=1).mean().reset_index(drop=True)\n",
    "    against_rolling = all_against_stats.groupby('TeamID').rolling(window=10, min_periods=1).mean().reset_index(drop=True)\n",
    "\n",
    "    stats_rolling = pd.concat([Week_DayNum_for, stats_rolling], axis=1)\n",
    "    # print(stats_rolling.columns)\n",
    "    # print(stats_rolling.head(29))\n",
    "    against_rolling = pd.concat([Week_DayNum_against, against_rolling], axis=1)\n",
    "\n",
    "    # # Calculate the mean for stats and stats against separately\n",
    "    # avg_stats = all_stats.groupby('TeamID').mean().reset_index()\n",
    "    # avg_against_stats = all_against_stats.groupby('TeamID').mean().reset_index()\n",
    "\n",
    "    merged_stats = pd.merge(stats_rolling, against_rolling, on=['TeamID','DayNum','Week'], suffixes=('', '_A'))\n",
    "    return merged_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "teams_stats_weekly_df = prepare_team_stats(games_df)\n",
    "# ordinal_df = ordinal_df.sort_values(by=['TeamID', 'RankingDayNum']).reset_index(drop=True)\n",
    "# ordinal_df = ordinal_df.rename(columns={'RankingDayNum':'DayNum'})\n",
    "\n",
    "# system_names = ordinal_df['SystemName'].unique()\n",
    "# teams_names = ordinal_df['TeamID'].unique()\n",
    "# system_no_rank_all_teams = []\n",
    "\n",
    "# for system in system_names:\n",
    "#     teams_in_system = ordinal_df[ordinal_df['SystemName'] == system]['TeamID'].unique()\n",
    "#     if len(teams_in_system) != len(teams_names):\n",
    "#         system_no_rank_all_teams.append(system)\n",
    "\n",
    "# ordinal_df = ordinal_df[~ordinal_df['SystemName'].isin(system_no_rank_all_teams)]\n",
    "# ordinal_pivot = ordinal_df.pivot_table(index=['TeamID', 'DayNum', 'Week'], columns='SystemName', values='OrdinalRank').reset_index()\n",
    "# ordinal_pivot.sort_values(by=['TeamID', 'DayNum'])\n",
    "# ordinal_pivot = ordinal_pivot.ffill()\n",
    "# ordinal_pivot = ordinal_pivot.groupby('TeamID').apply(lambda x: x.interpolate(method='linear', limit_direction='both')).reset_index(drop=True)\n",
    "\n",
    "ordinal_df = ordinal_df.sort_values(by=['TeamID']).reset_index(drop=True)\n",
    "ordinal_df = ordinal_df.drop(columns=['RankingDayNum'])\n",
    "\n",
    "system_names = ordinal_df['SystemName'].unique()\n",
    "teams_names = ordinal_df['TeamID'].unique()\n",
    "system_no_rank_all_teams = []\n",
    "\n",
    "for system in system_names:\n",
    "    teams_in_system = ordinal_df[ordinal_df['SystemName'] == system]['TeamID'].unique()\n",
    "    if len(teams_in_system) != len(teams_names):\n",
    "        system_no_rank_all_teams.append(system)\n",
    "\n",
    "ordinal_df = ordinal_df[~ordinal_df['SystemName'].isin(system_no_rank_all_teams)]\n",
    "ordinal_pivot = ordinal_df.pivot_table(index=['TeamID'], columns='SystemName', values='OrdinalRank').reset_index()\n",
    "ordinal_pivot.sort_values(by=['TeamID'])\n",
    "ordinal_pivot = ordinal_pivot.groupby('TeamID').mean().reset_index()\n",
    "\n",
    "\n",
    "ordinal_pivot.columns\n",
    "\n",
    "# ordinal_pivot[(ordinal_pivot['TeamID'] == 1104)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df[(games_df['WTeamID'] == 1104)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code performs the following operations:\n",
    "\n",
    "1. Sorts the 'ordinal_pivot' DataFrame by 'TeamID' and 'DayNum' columns.\n",
    "2. Sorts the 'teams_stats_weekly_df' DataFrame by 'TeamID' and 'DayNum' columns.\n",
    "3. Merges the sorted 'teams_stats_weekly_df' and 'ordinal_pivot' DataFrames using 'DayNum' and 'TeamID' columns in a backward direction.\n",
    "4. Sorts the resulting DataFrame by 'TeamID' and 'DayNum' columns and resets the index.\n",
    "5. Extracts the columns starting from the 35th column and assigns them to 'rank_columns' variable.\n",
    "6. Fills the missing values in 'rank_columns' for each 'TeamID' using backward filling.\n",
    "7. Filters the resulting DataFrame to include only rows where 'TeamID' is equal to 1104.\n",
    "\n",
    "Parameters:\n",
    "    - ordinal_pivot: DataFrame containing ordinal rankings.\n",
    "    - teams_stats_weekly_df: DataFrame containing weekly team statistics.\n",
    "\n",
    "Returns:\n",
    "    - weekly_stats_w_rating: DataFrame with sorted and merged data, filled with missing values, and filtered by 'TeamID' 1104.\n",
    "\"\"\"\n",
    "ordinal_pivot = ordinal_pivot.sort_values(by=['TeamID'])\n",
    "\n",
    "teams_stats_weekly_df = teams_stats_weekly_df.sort_values(by=['TeamID'])\n",
    "weekly_stats_w_rating = pd.merge(teams_stats_weekly_df, ordinal_pivot, on='TeamID', suffixes=('', '_A'))\n",
    "weekly_stats_w_rating = weekly_stats_w_rating.sort_values(by=['TeamID']).reset_index(drop=True)\n",
    "rank_columns = weekly_stats_w_rating.columns[34:]\n",
    "\n",
    "weekly_stats_w_rating[rank_columns] = weekly_stats_w_rating.groupby('TeamID')[rank_columns].bfill()\n",
    "weekly_stats_w_rating = weekly_stats_w_rating.dropna(axis = 1, how= 'any')\n",
    "weekly_stats_w_rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_matchup_data(games_df, stats):\n",
    "    \"\"\"\n",
    "    Merges game data with team stats to prepare matchup data.\n",
    "\n",
    "    Parameters:\n",
    "    - games_df (DataFrame): The DataFrame containing game results.\n",
    "    - avg_stats (DataFrame): The DataFrame containing average stats per team.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Matchup data with team stats and game outcome.\n",
    "    \"\"\"\n",
    "    stats.set_index('TeamID', inplace=True)\n",
    "    processed_data = []\n",
    "\n",
    "    for _, row in games_df.iterrows():\n",
    "        team_1, team_2 = sorted((row['WTeamID'], row['LTeamID']))\n",
    "        team_1_won = 1 if team_1 == row['WTeamID'] else 0\n",
    "        team_1_stats = stats.loc[team_1].add_prefix('team_1_').iloc[-1]\n",
    "        team_2_stats = stats.loc[team_2].add_prefix('team_2_').iloc[-1]\n",
    "        \n",
    "        matchup_data = {\n",
    "            'Season': row['Season'],\n",
    "            'DayNum': row['DayNum'],\n",
    "            'team_1': team_1,\n",
    "            'team_2': team_2,\n",
    "            'team_1_won': team_1_won\n",
    "        }\n",
    "        matchup_data.update(team_1_stats)\n",
    "        matchup_data.update(team_2_stats)\n",
    "\n",
    "        processed_data.append(matchup_data)\n",
    "\n",
    "    return pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = prepare_matchup_data(games_df, weekly_stats_w_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum().drop_duplicates()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_model_scalar(model_param, model_name, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3270)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Fit the model\n",
    "    model_param.fit(X_train_scaled, y_train)\n",
    "    y_pred = model_param.predict(X_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'{model_name} scalar accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model_param, model_name, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3270)\n",
    "\n",
    "    # sfs = SequentialFeatureSelector(model_param, n_features_to_select=10)\n",
    "    # sfs.fit(X_train, y_train)\n",
    "    # X_train = sfs.transform(X_train)\n",
    "    # X_test = sfs.transform(X_test)\n",
    "    model_param.fit(X_train, y_train)\n",
    "    y_pred = model_param.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'{model_name} accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matchups = prepare_matchup_data(games_df, weekly_stats_w_rating)\n",
    "\n",
    "X = test.drop(['DayNum','team_1_won'], axis=1)\n",
    "y = test['team_1_won']\n",
    "\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=3270, max_depth=10),\n",
    "    'Random Forest': RandomForestClassifier(random_state=3270, n_estimators=200, max_depth=10, min_samples_split=10),\n",
    "    'Logistic Regression': LogisticRegression(random_state=3270, max_iter=1000, penalty = None, solver = 'lbfgs', ),\n",
    "    'XGBoost': XGBClassifier(random_state = 3270, n_estimators = 100, max_depth = 3, learning_rate = 0.1, gamma = 0, subsample = 0.8, colsample_bytree = 0.8)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    fit_model_scalar(model, name, X, y)\n",
    "    fit_model(model, name, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(random_state=3270, max_iter=1000, penalty = None, solver = 'lbfgs')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3270)\n",
    "\n",
    "lgr.fit(X_train, y_train)\n",
    "y_pred = lgr.predict(X_test)\n",
    "#Show the predictions and the actual values side by side\n",
    "pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}).tail(50)\n",
    "#Show the accuracy of the predictions for the last 50 games\n",
    "accuracy_score(y_test[len(y_test)-200:], y_pred[len(y_test)-200:])\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_matchup_avgs_10_data = []\n",
    "for season in range(2003 , 2025):\n",
    "    season_games = pd.read_csv(f'{season}/MRegularSeasonDetailedResults_{season}_matchups_avg_w_rating.csv')\n",
    "    seasons_matchup_avgs_10_data.append(season_games)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeSeriesSplit_by_season(seasons_data):\n",
    "    \"\"\"\n",
    "    Splits the data into training and testing sets by season. Model is trained on all data up to a certain season and tested on the next season until the last season. \n",
    "\n",
    "    Parameters:\n",
    "    - seasons_data (list): A list of DataFrames containing data for each season.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of tuples containing training and testing sets for each season.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    model = LogisticRegression(random_state=3270, max_iter=1000, penalty = None, solver = 'lbfgs')\n",
    "    accuracies = []\n",
    "    for i in range(1, len(seasons_data)):\n",
    "        print(f'Testing on Season {seasons_data[i][\"Season\"].unique()[0]}')\n",
    "        train = pd.concat(seasons_data[:i])\n",
    "        train = train.dropna(axis = 'columns', how= 'any')\n",
    "        X_train = train.drop(['Season','DayNum', 'team_1_won'], axis=1)\n",
    "        y_train = train['team_1_won']\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        test = seasons_data[i]\n",
    "        test = test.dropna(axis = 'columns', how= 'any')\n",
    "        X_test = test.drop(['Season','DayNum', 'team_1_won'], axis=1)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        y_test = test['team_1_won']\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f'accuracy: {accuracy:.5f}')\n",
    "\n",
    "    print(f'Average accuracy: {np.mean(accuracies):.5f}')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeSeriesSplit_by_season(seasons_matchup_avgs_10_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_tourney_data = []\n",
    "for season in range(2003 , 2025):\n",
    "    season_games = pd.read_csv(f'{season}/MRegularSeasonCompactResults_{season}.csv')\n",
    "    seasons_tourney_data.append(season_games)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats_season = {}\n",
    "for season in range(2003 , 2025):\n",
    "    stats = pd.read_csv(f'{season}/MRegularSeasonDetailedResults_{season}_avg_w_rating.csv')\n",
    "    team_stats_season[season] = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_game_matchups(bracket_team_matchups, team_stats):\n",
    "    \"\"\"\n",
    "    Builds matchup data for the tournament bracket.\n",
    "\n",
    "    Parameters:\n",
    "    - bracket_team_matchups (DataFrame): The DataFrame containing the current matchups for a bracket.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: A DataFrame where each row contains team_1's and team_2's stats for that specific matchup.\n",
    "    \"\"\"\n",
    "    matchups = []\n",
    "    for _, row in bracket_team_matchups.iterrows():\n",
    "        team_1 = row['StrongSeed']\n",
    "        team_2 = row['WeakSeed']\n",
    "\n",
    "        team_1_data = team_stats[team_stats['TeamID'] == team_1]\n",
    "        team_2_data = team_stats[team_stats['TeamID'] == team_2]\n",
    "        \n",
    "        team_1_data.columns = [f'team_1_{col}' for col in team_1_data.columns]\n",
    "        team_2_data.columns = [f'team_2_{col}' for col in team_2_data.columns]\n",
    "        \n",
    "        team_1_data = team_1_data.reset_index(drop=True)\n",
    "        team_2_data = team_2_data.reset_index(drop=True)\n",
    "        matchup_data = pd.concat([team_1_data, team_2_data], axis=1)\n",
    "        matchup_data['Slot'] = row['Slot']\n",
    "        matchups.append(matchup_data)\n",
    "    return pd.concat(matchups, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_playins(seeds_df):\n",
    "    \"\"\"\n",
    "    Preprocess the play in teams by removing 'a' and 'b' designations and preparing strong and weak seeds.\n",
    "    \n",
    "    Parameters:\n",
    "    - seeds_df (DataFrame): The DataFrame containing tournament seeds data, including 'Seed', 'TeamID' columns.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Processed DataFrame with 'StrongSeed' and 'WeakSeed' for play-in teams.\n",
    "    \"\"\"\n",
    "    playin_teams = seeds_df[seeds_df['Seed'].str.contains('a') | seeds_df['Seed'].str.contains('b')].copy()\n",
    "    playin_teams['Seed'] = playin_teams['Seed'].str.extract('([0-9A-Z]+)')\n",
    "    playin_teams_match_df = playin_teams.groupby('Seed')['TeamID'].apply(list).reset_index()\n",
    "    playin_teams_match_df['StrongSeed'] = playin_teams_match_df['TeamID'].apply(lambda x: x[0])\n",
    "    playin_teams_match_df['WeakSeed'] = playin_teams_match_df['TeamID'].apply(lambda x: x[1])\n",
    "    playin_teams_match_df.rename(columns={'Seed': 'Slot'}, inplace=True)\n",
    "    return playin_teams_match_df.drop(columns='TeamID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bracket_winners(bracket_matchups, model, scalar):\n",
    "    \"\"\"\n",
    "    Predict the winners in the lower bracket using a pre-trained model and scaler.\n",
    "    \n",
    "    Parameters:\n",
    "    - bracket_matchups (DataFrame): DataFrame of matchups in the lower bracket, excluding 'Seed' from scaling.\n",
    "    - model (Model): Pre-trained prediction model.\n",
    "    - scalar (Scaler): Pre-fitted scaler object for normalizing data.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Lower bracket DataFrame with an additional column 'team_1_won' indicating the predicted winner.\n",
    "    \"\"\"\n",
    "    bracket_matchups = bracket_matchups.drop(columns= [])\n",
    "    lower_bracket_scaled = scalar.fit_transform(bracket_matchups.drop(columns=['Slot']))\n",
    "    bracket_matchups['team_1_won'] = model.predict(lower_bracket_scaled)\n",
    "    return bracket_matchups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_seeds_with_winners(bracket, seeds_df):\n",
    "    \"\"\"\n",
    "    Update the seeds DataFrame with the winners from the lower bracket predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    - bracket (DataFrame): The lower bracket DataFrame with predictions.\n",
    "    - seeds_df (DataFrame): The original seeds DataFrame to be updated with current teams seedings.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Updated seeds DataFrame with winners.\n",
    "    \"\"\"\n",
    "    bracket_winners = {}\n",
    "    for _, row in bracket.iterrows():\n",
    "        slot = row['Slot']\n",
    "        if slot not in bracket_winners:\n",
    "            bracket_winners[slot] = []\n",
    "        bracket_winners[slot].append(row['team_1_TeamID'] if row['team_1_won'] == 1 else row['team_2_TeamID'])\n",
    "    \n",
    "    for curr_seed, team in bracket_winners.items():\n",
    "        seeds_df.loc[len(seeds_df.index)] = [curr_seed, team[0]]\n",
    "    seeds_df.sort_values(by='Seed', inplace=True)\n",
    "    return seeds_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_round_matchups(team_seeds, round_slots):\n",
    "    \"\"\"\n",
    "    Build the Tourney round matchups based on seeds and updates team slots.\n",
    "    \n",
    "    Parameters:\n",
    "    - team_seeds (DataFrame): DataFrame containing the seeds and corresponding team IDs.\n",
    "    - round_slots (DataFrame): DataFrame containing the slots for the tournament matchups.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: First-round matchups with updated team slots based on seeds.\n",
    "    \"\"\"\n",
    "\n",
    "    for index, row in round_slots.iterrows():\n",
    "        strong_team = team_seeds[(team_seeds['Seed'] == row['StrongSeed'])]['TeamID'].values[0]\n",
    "        weak_team = team_seeds[(team_seeds['Seed'] == row['WeakSeed'])]['TeamID'].values[0]\n",
    "        round_slots.at[index, 'StrongSeed'] = strong_team\n",
    "        round_slots.at[index, 'WeakSeed'] = weak_team\n",
    "\n",
    "    return round_slots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourney_seeds_df = pd.read_csv('2023/MNCAATourneySeeds_2023.csv')\n",
    "tourney_seeds_df.drop(columns=['Season'], inplace=True)\n",
    "tourney_slots_df = pd.read_csv('2023/MNCAATourneySlots_2023.csv')\n",
    "\n",
    "scalar = StandardScaler()\n",
    "\n",
    "playin_teams_match_df = preprocess_playins(tourney_seeds_df)\n",
    "bracket_matchups = build_game_matchups(playin_teams_match_df, team_stats_season[2023].groupby('TeamID').last().reset_index())\n",
    "bracket_matchups.columns\n",
    "bracket_matchups = predict_bracket_winners(bracket_matchups, model, scalar)\n",
    "tourney_seeds_df = update_seeds_with_winners(bracket_matchups, tourney_seeds_df)\n",
    "print('Done with play-ins')\n",
    "\n",
    "\n",
    "# curr_round_slots = tourney_slots_df[tourney_slots_df['Slot'].str.contains('R1')]\n",
    "\n",
    "# round_df = build_round_matchups(tourney_seeds_df,curr_round_slots)\n",
    "\n",
    "# current_round_bracket = build_game_matchups(round_df, team_stats_season[2023])\n",
    "# current_round_bracket.reset_index(drop=True, inplace=True)\n",
    "# current_round_bracket = predict_bracket_winners(current_round_bracket, model, scalar)\n",
    "# tourney_seeds_df = update_seeds_with_winners(current_round_bracket, tourney_seeds_df)\n",
    "\n",
    "\n",
    "rounds = ['R1', 'R2', 'R3', 'R4', 'R5', 'R6']\n",
    "# rounds = ['R1']\n",
    "matchups = []\n",
    "for current_round in rounds:\n",
    "    curr_round_slots = tourney_slots_df[tourney_slots_df['Slot'].str.contains(current_round)]\n",
    "\n",
    "    round_matchups = build_round_matchups(tourney_seeds_df,curr_round_slots)\n",
    "    matchups.append(round_matchups)\n",
    "    current_round_bracket = build_game_matchups(round_matchups, team_stats_season[2023].groupby('TeamID').last().reset_index())\n",
    "    current_round_bracket = predict_bracket_winners(current_round_bracket, model, scalar)\n",
    "    tourney_seeds_df = update_seeds_with_winners(current_round_bracket, tourney_seeds_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_bracket = pd.concat(matchups)\n",
    "complete_bracket.reset_index(drop=True, inplace=True)\n",
    "# complete_bracket.to_csv('2023/MNCAATourneyPredictions_matchup_2023.csv', index=False)\n",
    "complete_bracket\n",
    "\n",
    "# tourney_seeds_df\n",
    "# test_dict = {}\n",
    "# test_dict[type(lgr).__name__] = [accuracy_score(y_test, y_pred)]\n",
    "# test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_save_load_all_models as tsm\n",
    "import os\n",
    "\n",
    "\n",
    "models = tsm.load_models()\n",
    "for model_name, model in models['avg_10'].items():\n",
    "    print(model_name)\n",
    "    print(model)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
